{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import math \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import opencv_jupyter_ui as jcv2\n",
    "\n",
    "## Libraries \n",
    "from src.Motion_Control import thymio as th\n",
    "from src.Global_Nav import helpers_global as gb\n",
    "from src.Vision import vision as vs\n",
    "#import filtering \n",
    "from src.Local_Nav import psymap as pm  \n",
    "from src.Local_Nav import local_navigation as ln\n",
    "from src.Filtering import filtering\n",
    "import PID \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the path planning we choose the A\\* Algorithm with the occupancy grid given by the vision module. We choosed to use A\\* as it is the simplest algorithm to have the optimal path\n",
    "To have a margin to the obtacle we modified the cost of the cell by multipliying it by 2 if the cell is in a radius of 3 cells from an obstacle and by 1.5 if the cell is in a radius of 5 cell from the obstacle.\n",
    "\n",
    "We also used the Douglas Peucker algorithm to simplify the path given by A\\*, and have a smoother trajectory. \n",
    "Finally, we decided to use a path containing only the points where the direction is changing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Global Naviguation**\n",
    "\n",
    "All the global naviguation function are grouped in the folder `helpers_global`.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### A\\* computation\n",
    "Since we are working with a grid filled with 1 for global obstacles and 0 for free cells, we are using the same A\\* algorithm as the one in the exercise on Path Planning. We made a couple changes to adapt it to the project. Note that the grid computed by the vision is taking into account the size of the robot so the obstacles are bigger than in reality. After getting, the start and goal position from the camera, we can use the  `global_final` function to get the path that is already simplified by the Douglas Peucker algorithm. It also use a VISUALIZE parameter that plot the path computed on the given grid. To naviguate further from the global obstacles, we added a cost on the gScore if the cell is near an obstacle. We computed an safety margin that multiplies the current cost (the default one is 1) that is add to gScore : \n",
    "\n",
    "<small>\n",
    "\n",
    "```python\n",
    "def calculate_safety_margin(neighbor, occupancy_grid):\n",
    "    distance_threshold_big = 5  \n",
    "    distance_threshold_small = 3\n",
    "    distance_to_obstacle = distance_to_nearest_obstacle(neighbor, occupancy_grid)\n",
    "\n",
    "    if distance_to_obstacle < distance_threshold_big:\n",
    "        if distance_to_obstacle < distance_threshold_small:\n",
    "            safety_margin = 2     \n",
    "        else: \n",
    "            safety_margin = 1.5  \n",
    "    else:\n",
    "        safety_margin = 1.0  \n",
    "\n",
    "    return safety_margin\n",
    "\n",
    "```\n",
    "\n",
    "</small>\n",
    "\n",
    "where `distance_to_nearest_obstacle` gives the minimal distance to any obstacles in the grid\n",
    "\n",
    "\n",
    "### Douglas-Peucker Algorithm\n",
    "\n",
    "Since the path given by A\\* is giving points on the grid and therefore is often changing in direction we simplified it by the Douglas Peucker Algorithm:\n",
    "\n",
    "<small>\n",
    "\n",
    "```python\n",
    "def douglas_peucker(coords, epsilon):\n",
    "    if len(coords) <= 2:\n",
    "        return [coords[0], coords[-1]]\n",
    "\n",
    "    dmax = 0\n",
    "    index = 0\n",
    "    end = len(coords) - 1\n",
    "    for i in range(1, end):\n",
    "        d = point_to_line_distance(coords[i], coords[0], coords[end])\n",
    "        if d > dmax:\n",
    "            index = i\n",
    "            dmax = d\n",
    "\n",
    "    if dmax > epsilon:\n",
    "        results1 = douglas_peucker(coords[:index + 1], epsilon)\n",
    "        results2 = douglas_peucker(coords[index:], epsilon)\n",
    "\n",
    "        results = results1[:-1] + results2\n",
    "    else:\n",
    "        results = [coords[0], coords[end]]\n",
    "\n",
    "    return results\n",
    "```\n",
    "\n",
    "</small>\n",
    "\n",
    "It is a recursive algorithm that take the path in argument and give a simplified one that only keep the point with big variation in between\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Node 7648c768-a4cd-4427-9998-204136028638"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tdmclient import ClientAsync\n",
    "client = ClientAsync()\n",
    "node = await client.wait_for_node() #_ = protected #__ = private = shouldn't access node outside of the class\n",
    "await node.lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Constant \n",
    "MAP_SHAPE = (1000,700)\n",
    "REFRAME = True \n",
    "TS =0.01\n",
    "EPSILON_ANGLE= np.pi/4\n",
    "VISUALIZE = True\n",
    "MAP_SHAPE_MM = (1000,700)\n",
    "MAP_SHAPE_CELL = (50,35)\n",
    "ROBROAD = 110\n",
    "SIMPLIFY = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[997, 998]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await th.get_proximity_ground_values(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the camera : 25sec\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jujud\\Documents\\MobileRoboticsG16\\Main_julien.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jujud/Documents/MobileRoboticsG16/Main_julien.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m path, state_estimation_prev2, P_estimation_prev \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39;49minit(cap, REFRAME, MAP_SHAPE, VISUALIZE,ROBROAD, SIMPLIFY )\n",
      "File \u001b[1;32mc:\\Users\\jujud\\Documents\\MobileRoboticsG16\\src\\Motion_Control\\thymio.py:118\u001b[0m, in \u001b[0;36minit\u001b[1;34m(cap, REFRAME, MAP_SHAPE, VISUALIZE, robroad2, simplify)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minit\u001b[39m(cap, REFRAME, MAP_SHAPE, VISUALIZE,robroad2 \u001b[39m=\u001b[39m \u001b[39m80\u001b[39m,  simplify\u001b[39m=\u001b[39m\u001b[39m0.8\u001b[39m): \n\u001b[0;32m    115\u001b[0m     \u001b[39m# Get the path \u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[39mif\u001b[39;00m REFRAME:\n\u001b[1;32m--> 118\u001b[0m         Tmap \u001b[39m=\u001b[39m vs\u001b[39m.\u001b[39;49mget_warp(cap,MAP_SHAPE,\u001b[39m10\u001b[39;49m,\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    120\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m         ret,frame \u001b[39m=\u001b[39m cap\u001b[39m.\u001b[39mread()\n",
      "File \u001b[1;32mc:\\Users\\jujud\\Documents\\MobileRoboticsG16\\src\\Vision\\vision.py:100\u001b[0m, in \u001b[0;36mget_warp\u001b[1;34m(cap, ROI, pad, samples, verbose)\u001b[0m\n\u001b[0;32m     98\u001b[0m corners \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39m4\u001b[39m,\u001b[39m2\u001b[39m,samples))\n\u001b[0;32m     99\u001b[0m \u001b[39mwhile\u001b[39;00m smp \u001b[39m<\u001b[39m samples:\n\u001b[1;32m--> 100\u001b[0m     ret, frame \u001b[39m=\u001b[39m cap\u001b[39m.\u001b[39;49mread()\n\u001b[0;32m    101\u001b[0m     \u001b[39mif\u001b[39;00m ret:\n\u001b[0;32m    102\u001b[0m         hslimg \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(frame, cv2\u001b[39m.\u001b[39mCOLOR_BGR2HLS_FULL)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path, state_estimation_prev2, P_estimation_prev = th.init(cap, REFRAME, MAP_SHAPE, VISUALIZE,ROBROAD, SIMPLIFY )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for destination...\n",
      "Warning: 0 goals found\r"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - imshow() missing required argument 'winname' (pos 1)\n>  - imshow() missing required argument 'winname' (pos 1)\n>  - imshow() missing required argument 'winname' (pos 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jujud\\Documents\\MobileRoboticsG16\\Main_julien.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jujud/Documents/MobileRoboticsG16/Main_julien.ipynb#X21sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jujud/Documents/MobileRoboticsG16/Main_julien.ipynb#X21sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jujud/Documents/MobileRoboticsG16/Main_julien.ipynb#X21sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m         cv2\u001b[39m.\u001b[39;49mimshow()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jujud/Documents/MobileRoboticsG16/Main_julien.ipynb#X21sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jujud/Documents/MobileRoboticsG16/Main_julien.ipynb#X21sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNo camera !\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - imshow() missing required argument 'winname' (pos 1)\n>  - imshow() missing required argument 'winname' (pos 1)\n>  - imshow() missing required argument 'winname' (pos 1)\n"
     ]
    }
   ],
   "source": [
    "#setup\n",
    "if REFRAME:\n",
    "    Tmap = vs.get_warp(cap,MAP_SHAPE_MM,20,10)\n",
    "\n",
    "ret,frame = cap.read()\n",
    "if ret:\n",
    "    if REFRAME:\n",
    "        frame = cv2.warpPerspective(frame,Tmap,MAP_SHAPE_MM)\n",
    "    fmap = vs.get_grid_fixed_map(frame,MAP_SHAPE_CELL, robrad=50)\n",
    "    obscont = vs.get_obstacles(frame)\n",
    "    print(\"Searching for destination...\")\n",
    "    while True:\n",
    "        ret,frame = cap.read()\n",
    "        if ret:\n",
    "            if REFRAME:\n",
    "                frame = cv2.warpPerspective(frame,Tmap,MAP_SHAPE_MM)\n",
    "            ret,destmm = vs.get_destination(frame)\n",
    "            if ret:\n",
    "                dest = gb.convert_to_idx([coord / 10.0 for coord in destmm],2)\n",
    "                dest[1]= 35-dest[1]\n",
    "                dest = tuple(dest)\n",
    "                break\n",
    "            else:\n",
    "                cv2.imshow()\n",
    "        else:\n",
    "            print(\"No camera !\")\n",
    "            break\n",
    "    print(\"Found destination Point at {} [mm] {} [cells]\".format(destmm,dest))\n",
    "    print(\"Searching for Robot...\")\n",
    "    while True:\n",
    "        ret,frame = cap.read()\n",
    "        if ret:\n",
    "            if REFRAME:\n",
    "                frame = cv2.warpPerspective(frame,Tmap,MAP_SHAPE_MM)\n",
    "            hls_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HLS_FULL) \n",
    "            ret,robpos,orient,pxpcm = vs.get_Robot_position_orientation(hls_frame)\n",
    "            if ret:\n",
    "                print(\"Robot found at {} [mm], {} [rad]\".format(robpos,orient))\n",
    "                break\n",
    "        else:\n",
    "            print(\"No camera !\")\n",
    "            break\n",
    "\n",
    "start = gb.convert_to_idx(robpos,20)\n",
    "start[1]= MAP_SHAPE_CELL[1]-start[1]\n",
    "start = tuple(start)\n",
    "path = gb.global_final(fmap,start,dest, \"8N\", VISUALIZE)\n",
    "\n",
    "state_estimation_prev2 = np.array([[robpos[0]],[700-robpos[1]], [orient], [0], [0]])\n",
    "P_estimation_prev =  np.diag([100, 100, 0.75, 10, 0.75])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = gb.convert_to_idx(robpos,20)\n",
    "start[1]= MAP_SHAPE_CELL[1]-start[1]\n",
    "start = tuple(start)\n",
    "path = gb.global_final(fmap,start,dest, \"8N\", VISUALIZE)\n",
    "\n",
    "state_estimation_prev2 = np.array([[robpos[0]],[700-robpos[1]], [orient], [0], [0]])\n",
    "P_estimation_prev =  np.diag([100, 100, 0.75, 10, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dest_prev' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jujud\\Documents\\MobileRoboticsG16\\Main_julien.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jujud/Documents/MobileRoboticsG16/Main_julien.ipynb#W5sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     dest[\u001b[39m1\u001b[39m]\u001b[39m=\u001b[39m \u001b[39m35\u001b[39m\u001b[39m-\u001b[39mdest[\u001b[39m1\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jujud/Documents/MobileRoboticsG16/Main_julien.ipynb#W5sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     dest \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(dest)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jujud/Documents/MobileRoboticsG16/Main_julien.ipynb#W5sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mif\u001b[39;00m dest \u001b[39m!=\u001b[39m dest_prev : \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jujud/Documents/MobileRoboticsG16/Main_julien.ipynb#W5sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     start \u001b[39m=\u001b[39m gb\u001b[39m.\u001b[39mconvert_to_idx(center,\u001b[39m20\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jujud/Documents/MobileRoboticsG16/Main_julien.ipynb#W5sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     start \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(start)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dest_prev' is not defined"
     ]
    }
   ],
   "source": [
    "##Main boucle with Kalman Aubin\n",
    "\n",
    "local_obstacle = False\n",
    "counter=0\n",
    "record= []\n",
    "\n",
    "check=[]\n",
    "check_point_prev=np.array([0,0])\n",
    "\n",
    "start_time = time.time()\n",
    "kidnapping_state = False\n",
    "\n",
    "state_estimation_prev= state_estimation_prev2\n",
    "Tmap = vs.get_warp(cap,MAP_SHAPE,10,1)\n",
    "while True:\n",
    "    \n",
    "    \n",
    "\n",
    "    ret,frame = cap.read()\n",
    "    if ret : \n",
    "        \n",
    "        # maps capture to map\n",
    "        if REFRAME:\n",
    "            frame = cv2.warpPerspective(frame,Tmap,MAP_SHAPE)\n",
    "        # maps BGR to HLS color space for simplicity\n",
    "        HLS = cv2.cvtColor(frame, cv2.COLOR_BGR2HLS_FULL)\n",
    "\n",
    "        bool_pos ,center,orient, scale = vs.get_Robot_position_orientation(HLS, 5)\n",
    "        if bool_pos : \n",
    "            #center = center/20.0\n",
    "            center[1] = 700- center[1]\n",
    "            orient2 = orient\n",
    "            if orient <0:\n",
    "                orient = orient +2*np.pi\n",
    "            x_est_cam = np.array([center[0], center[1], orient])\n",
    "            marre = np.array([x_est_cam[0]/20, x_est_cam[1]/20, orient2])\n",
    "            record.append(marre)\n",
    "            \n",
    "        else :\n",
    "            x_est_cam = None\n",
    "        ground_values = await th.get_proximity_ground_values(client)\n",
    "        \"\"\"\"\"\n",
    "        ret2,destmm = vs.get_destination(frame)\n",
    "        if ret2:\n",
    "            dest = gb.convert_to_idx([coord / 10.0 for coord in destmm],2)\n",
    "            dest[1]= 35-dest[1]\n",
    "            dest = tuple(dest)\n",
    "        \n",
    "        if dest != dest_prev : \n",
    "            start = gb.convert_to_idx(center,20)\n",
    "            start = tuple(start)\n",
    "            path = gb.global_final(fmap,start,dest, \"8N\", VISUALIZE)\n",
    "            state_estimation_prev = np.array([[center[0]],[center[1]], [orient], [0], [0]])\n",
    "            P_estimation_prev =  np.diag([100, 100, 0.75, 10, 0.75])\n",
    "            counter =0\n",
    "            check_point_prev=np.array([0,0])\n",
    "            start_time = time.time()\n",
    "        \n",
    "        else :\n",
    "            dest_prev = dest\n",
    "        \"\"\"\n",
    "        if(ground_values[0]<300 or ground_values[1]< 300):\n",
    "            print('Kidnapping detected')\n",
    "            await th.stop_motor(node)\n",
    "            kidnapping_state= True\n",
    "\n",
    "        if ground_values[0]>300 and ground_values[1]>300 and kidnapping_state and bool_pos:\n",
    "\n",
    "            kidnapping_state = False\n",
    "            start = gb.convert_to_idx(center,20)\n",
    "            start = tuple(start)\n",
    "            path = gb.global_final(fmap,start,dest, \"8N\", VISUALIZE)\n",
    "            state_estimation_prev = np.array([[center[0]],[center[1]], [orient], [0], [0]])\n",
    "            P_estimation_prev =  np.diag([100, 100, 0.75, 10, 0.75])\n",
    "            counter =0\n",
    "            check_point_prev=np.array([0,0])\n",
    "            start_time = time.time()\n",
    "     \n",
    "        if not kidnapping_state:\n",
    "            if x_est_cam is not None: \n",
    "                if abs(state_estimation[2][0]-x_est_cam[2] )>1:\n",
    "                    x_est_cam = None\n",
    "            state_estimation, P_estimation, speed, angular_speed, start_time, angle = await filtering.get_position(state_estimation_prev, P_estimation_prev, start_time,bool_pos,x_est_cam, node )\n",
    "            state_estimation_prev = state_estimation\n",
    "            P_estimation_prev = P_estimation\n",
    "\n",
    "            position = np.array([state_estimation[0].item(), state_estimation[1].item()])\n",
    "            theta = angle\n",
    "            position = position / 20.0\n",
    "            position_array = np.array(position)\n",
    "            \n",
    "        \n",
    "            \n",
    "            check_point, counter = gb.next_checkpoint2(path, position, counter,local_obstacle)\n",
    "        # if theta > np.pi :\n",
    "            # theta = theta-2*np.pi\n",
    "        # if theta < -np.pi:\n",
    "            #  theta = theta+ 2*np.pi    \n",
    "                \n",
    "            marre2 = np.array([position_array[0], position_array[1], theta[0]])\n",
    "            check.append(marre2)\n",
    "            if np.any(check_point_prev != check_point):\n",
    "                print(f\"Le robot est en position de {position}, converti en index {gb.convert_to_idx(position, 1)} et le prochain check point est {check_point}\")\n",
    "                check_point_prev = check_point\n",
    "                \n",
    "            if abs(position[0]-path[-1][0])<1 and abs(position[1]-path[-1][1])<1:\n",
    "                await th.stop_motor(node)\n",
    "                break\n",
    "\n",
    "            angle_error=  theta-th.compute_angle(gb.convert_to_idx(position,1), path[counter])\n",
    "            if angle_error > np.pi :\n",
    "                angle_error = angle_error-2*np.pi\n",
    "            if angle_error < -np.pi:\n",
    "                angle_error = angle_error+ 2*np.pi\n",
    "\n",
    "        \n",
    "            #local nav\n",
    "            #sensor values\n",
    "            obscont = vs.get_obstacles(frame, robrad = 10)\n",
    "            capthall = pm.hallucinate_map([position[0],position[1],(-orient)],obscont)\n",
    "            sens = await th.get_proximity_values(client)\n",
    "            if (sum(sens[i] > 1000 for i in range(0, 5)) > 0):#before 2500\n",
    "                local_obstacle = True\n",
    "\n",
    "            if(local_obstacle):\n",
    "                print(\"local nav on\")\n",
    "                await ln.local_navigation2(client,node,[position[0],position[1],(-orient)],obscont)\n",
    "            \n",
    "                if(not sum(sens[i] > 1000 for i in range(0, 5)) > 0):\n",
    "                    await th.motorset(node,100,100)\n",
    "                    time.sleep(2)\n",
    "                    local_obstacle = False\n",
    "            #motor control\n",
    "            else :\n",
    "                if(angle_error>EPSILON_ANGLE):\n",
    "                    await th.motorset(node,70,-70)\n",
    "                elif (angle_error<-EPSILON_ANGLE):\n",
    "                    await th.motorset(node,-70,70)\n",
    "                else:\n",
    "                    speed_l, speed_r = PID.PIDController(50,100, angle_error)\n",
    "                    await th.motorset(node,speed_l,speed_r)\n",
    "                \n",
    "    await client.sleep(TS)      \n",
    "   \n",
    "if VISUALIZE :\n",
    "    x_values = [coord[0] for coord in check]\n",
    "    y_values = [coord[1] for coord in check]\n",
    "    x_path =   [coord[0] for coord in path]\n",
    "    y_path =  [coord[1] for coord in path]\n",
    "\n",
    "    # Tracer le graphique x en fonction de y\n",
    "    plt.plot(x_values, y_values, marker='.', linestyle='-')\n",
    "    plt.plot(x_path, y_path, marker ='o', color = 'red')\n",
    "    plt.title('Graphique de x en fonction de y')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "           \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "await th.stop_motor(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le robot est en position de [40.7   3.85], converti en index [40, 3] et le prochain check point est [45  8]\n",
      "local nav onalid samples\n",
      "Le robot est en position de [43.4  5.9], converti en index [43, 5] et le prochain check point est [39 19]\n",
      "local nav on\n",
      "local nav onalid samples\n",
      "local nav onalid samples\n",
      "shape points 0/3 samples\r"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jujud\\Documents\\MobileRoboticsG16\\Main_julien.ipynb Cell 8\u001b[0m line \u001b[0;36m8\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jujud/Documents/MobileRoboticsG16/Main_julien.ipynb#X10sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jujud/Documents/MobileRoboticsG16/Main_julien.ipynb#X10sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m                 \u001b[39mawait\u001b[39;00m th\u001b[39m.\u001b[39mmotorset(node,\u001b[39m120\u001b[39m,\u001b[39m120\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jujud/Documents/MobileRoboticsG16/Main_julien.ipynb#X10sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m \u001b[39mawait\u001b[39;00m client\u001b[39m.\u001b[39msleep(TS)      \n",
      "File \u001b[1;32mc:\\Users\\jujud\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tdmclient\\clientasync.py:73\u001b[0m, in \u001b[0;36mClientAsync.sleep\u001b[1;34m(self, duration, wake)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[39mif\u001b[39;00m wake \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m wake():\n\u001b[0;32m     72\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m \u001b[39myield\u001b[39;00m\n",
      "\u001b[1;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "## Main boucle with local nav without filtering \n",
    "\n",
    "local_obstacle = False\n",
    "counter=0\n",
    "record= []\n",
    "angle =[]\n",
    "check=[]\n",
    "check_point_prev=np.array([0,0])\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    Tmap = vs.get_warp(cap,MAP_SHAPE,10,1)\n",
    "    if ret:\n",
    "        # maps capture to map\n",
    "        if REFRAME:\n",
    "            frame = cv2.warpPerspective(frame,Tmap,MAP_SHAPE)\n",
    "        # maps BGR to HLS color space for simplicity\n",
    "        HLS = cv2.cvtColor(frame, cv2.COLOR_BGR2HLS_FULL)\n",
    "        obscont = vs.get_obstacles(frame, robrad = 10)\n",
    "        bool_pos ,center,orient, scale = vs.get_Robot_position_orientation(HLS, 5)\n",
    "        if bool_pos : \n",
    "            center = center/20.0\n",
    "            center[1] = 35- center[1]\n",
    "            \n",
    "            x_est_cam = [center[0], center[1], orient]\n",
    "            \n",
    "            record.append(x_est_cam)\n",
    "        #if VISUALIZE:\n",
    "            #vizu = vs.visualizer(HLS)\n",
    "            #omap =vs.grid_fixedmap_visualizer(fmap.transpose(),MAP_SHAPE_MM)\n",
    "            #obsimg = cv2.merge([omap,omap,omap])\n",
    "            #vizu = cv2.bitwise_or(vizu,obsimg)\n",
    "            #vizu = vs.draw_obstacles_poly(vizu,obscont,(255,255,0),2)\n",
    "            #vizu = cv2.circle(vizu,destmm,20,(50,25,100),4)\n",
    "           # vizu = cv2.addWeighted(vizu,0.5,frame,0.5,0)\n",
    "            #if bool_pos:\n",
    "                #vizu = show_path(vizu,path,20,center)\n",
    "                #vizu = vs.paint_robot(vizu,(0,0,200),center,orient,scale)\n",
    "                #vizu = pm.hallucinate_map([center[0],center[1],(-orient)],obscont,vizu)\n",
    "            \n",
    "           # jcv2.imshow(\"Map\",vizu)\n",
    "           # if jcv2.waitKey(1) & 0xFF == ord('q'):\n",
    "               # break\n",
    "        if bool_pos : \n",
    "            check_point, counter = gb.next_checkpoint2(path, center, counter,local_obstacle)\n",
    "            #print(counter)\n",
    "            check.append(counter)\n",
    "            if np.any(check_point_prev != check_point):\n",
    "                print(f\"Le robot est en position de {center}, converti en index {gb.convert_to_idx(center, 1)} et le prochain check point est {check_point}\")\n",
    "                check_point_prev = check_point\n",
    "                \n",
    "            if abs(center[0]-path[-1][0])<1 and abs(center[1]-path[-1][1])<1:\n",
    "                await th.stop_motor(node)\n",
    "                break\n",
    "\n",
    "            angle_error=  orient-th.compute_angle(gb.convert_to_idx(center,1), path[counter])\n",
    "            if angle_error > np.pi :\n",
    "                angle_error = angle_error-2*np.pi\n",
    "            if angle_error < -np.pi:\n",
    "                angle_error = angle_error+ 2*np.pi\n",
    "\n",
    "            #print(f\"L'angle du robot est {orient} et l'angle vers le goal est {th.compute_angle(gb.convert_to_idx(center,1) , check_point)} et l'angle error est {angle_error}\")\n",
    "            angle.append(angle_error)\n",
    "            #local nav\n",
    "            #sensor values\n",
    "            capthall = pm.hallucinate_map([center[0],center[1],(-orient)],obscont)\n",
    "            sens = await th.get_proximity_values(client)\n",
    "            if (sum(sens[i] > 500 for i in range(0, 5)) > 0):\n",
    "                local_obstacle = True\n",
    "\n",
    "            if(local_obstacle):\n",
    "                print(\"local nav on\")\n",
    "                await ln.local_navigation(client,node,[center[0],center[1],(-orient)],obscont)\n",
    "                \n",
    "                if(not sum(sens[i] > 500 for i in range(0, 5)) > 0):\n",
    "                    await th.motorset(node,100,100)\n",
    "                    await client.sleep(1.5)\n",
    "                    local_obstacle = False\n",
    "                \n",
    "            #motor control\n",
    "            else :\n",
    "                if(angle_error>EPSILON_ANGLE):\n",
    "                    await th.motorset(node,70,-70)\n",
    "                elif (angle_error<-EPSILON_ANGLE):\n",
    "                    await th.motorset(node,-70,70)\n",
    "                else:\n",
    "                    await th.motorset(node,120,120)\n",
    "            \n",
    "    await client.sleep(TS)      \n",
    "\n",
    "\n",
    "if VISUALIZE : \n",
    "    x_values = [coord[0] for coord in record]\n",
    "    y_values = [coord[1] for coord in record]\n",
    "    x_path =   [coord[0] for coord in path]\n",
    "    y_path =  [coord[1] for coord in path]\n",
    "\n",
    "    # Tracer le graphique x en fonction de y\n",
    "    plt.plot(x_values, y_values, marker='.', linestyle='-')\n",
    "    plt.plot(x_path, y_path, marker ='o', color = 'red')\n",
    "    plt.title('Graphique de x en fonction de y')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await th.stop_motor(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path, state_estimation_prev2, P_estimation_prev = th.init(cap, REFRAME, MAP_SHAPE, VISUALIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MAIN boucle with kalman aubin debug \n",
    "\n",
    "t = 0\n",
    "local_obstacle = False\n",
    "counter=0\n",
    "record= []\n",
    "angle =[]\n",
    "check=[]\n",
    "check_point_prev=np.array([0,0])\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "norm_distance=[]\n",
    "state_estimation_prev= state_estimation_prev2\n",
    "\n",
    "while True:\n",
    "    #node = await client.wait_for_node()\n",
    "    ret,frame = cap.read()\n",
    "    Tmap = vs.get_warp(cap,MAP_SHAPE,10,1)\n",
    "    \n",
    "    if ret:\n",
    "        # maps capture to map\n",
    "        if REFRAME:\n",
    "            frame = cv2.warpPerspective(frame,Tmap,MAP_SHAPE)\n",
    "        # maps BGR to HLS color space for simplicity\n",
    "        HLS = cv2.cvtColor(frame, cv2.COLOR_BGR2HLS_FULL)\n",
    "\n",
    "        bool_pos ,center,orient, scale = vs.get_Robot_position_orientation(HLS, 5)\n",
    "        if bool_pos : \n",
    "            #center = center/20.0\n",
    "            center[1] = 700- center[1]\n",
    "            x_est_cam = np.array([center[0], center[1], orient])\n",
    "            marre = np.array([x_est_cam[0]/20, x_est_cam[1]/20, orient, t])\n",
    "            record.append(marre)\n",
    "            #print(x_est_cam)\n",
    "        else :\n",
    "            x_est_cam = None\n",
    "    \n",
    "    else :\n",
    "        x_est_cam = None\n",
    "        bool_pos = False\n",
    "        \n",
    "    \n",
    "    \n",
    "   # state_estimation, P_estimation, speed, angular_speed = await filtering.get_position2(state_estimation_prev, P_estimation_prev, TS, bool_pos, x_est_cam, node)\n",
    "    state_estimation, P_estimation, speed, angular_speed, start_time = await filtering.get_position(state_estimation_prev, P_estimation_prev, start_time,False,None, node, TS )\n",
    "   \n",
    "    state_estimation_prev = state_estimation\n",
    "    P_estimation_prev = P_estimation\n",
    "\n",
    "    position = np.array([state_estimation[0].item(), state_estimation[1].item()])\n",
    "    theta = state_estimation[2]\n",
    "    if theta > np.pi :\n",
    "        theta = theta-2*np.pi\n",
    "    if theta < -np.pi:\n",
    "        theta = theta+ 2*np.pi    \n",
    "    \n",
    "    position = position / 20.0\n",
    "    position_array = np.array(position)\n",
    "    marre2 = np.array([position_array[0], position_array[1], theta[0], t])\n",
    "    check.append(marre2)\n",
    "    \n",
    "    \"\"\"\"\"\n",
    "    await th.motorset(node,120,120)\n",
    "    print(f\"La distance du depart est {np.sqrt((position[0]-state_estimation_prev2[0][0]/20)**2 + (position[1]-state_estimation_prev2[1][0]/20)**2)} \")\n",
    "    if np.sqrt((position[0]-state_estimation_prev2[0][0]/20)**2 + (position[1]-state_estimation_prev2[1][0]/20)**2) >10:\n",
    "        await th.stop_motor(node)\n",
    "        break\n",
    "    \"\"\"\n",
    "    await th.motorset(node,-70,70)\n",
    "    #print(f\"La distance du depart est {np.sqrt((position[0]-state_estimation_prev2[0][2]/20)**2 + (position[1]-state_estimation_prev2[1][0]/20)**2)} \")\n",
    "    print (f\"la diff d'angle vaut {theta -state_estimation_prev2[2][0]}\")\n",
    "    if t > 50:\n",
    "        await th.stop_motor(node)\n",
    "        break\n",
    "    t= t+1       \n",
    "    await client.sleep(TS)      \n",
    "   \n",
    "     \n",
    "           \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await th.stop_motor(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To unlock the Robot\n",
    "await node.unlock()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
